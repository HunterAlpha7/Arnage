{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HunterAlpha7/Arnage/blob/main/SIM_Lab_Assignment_2_Seyam_1066.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Name:** *Seyam Bin H Rahman*  \n",
        "**ID:** *0432220005101066*  \n",
        "**Section:** 7A"
      ],
      "metadata": {
        "id": "Hs4j8P_RUIE6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part C: Practice Questions"
      ],
      "metadata": {
        "id": "PartC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Suppose α = 0.05.  \n",
        "   (a) If p = 0.03, H1 wins (reject H0). Why? Because p-value (0.03) is less than α (0.05), indicating strong evidence against H0.  \n",
        "   (b) If p = 0.08, H0 wins (fail to reject H0). Why? Because p-value (0.08) is greater than α (0.05), indicating not enough evidence against H0."
      ],
      "metadata": {
        "id": "Q1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. In my own words: We need α in hypothesis testing to set a threshold for the risk of falsely rejecting the null hypothesis (Type I error). It helps decide if the evidence is strong enough. If the p-value is very small, it means the data we observed is highly unlikely if H0 were true, so we have strong evidence to reject H0 and support H1."
      ],
      "metadata": {
        "id": "Q2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. My own example with α = 0.01: Testing if the average exam score of a class is 65 (H0: μ = 65, H1: μ ≠ 65). I'll show two cases using simulated data."
      ],
      "metadata": {
        "id": "Q3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJiw90Ziikfi"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Case 1: H1 wins (p-value < 0.01)"
      ],
      "metadata": {
        "id": "Case1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# last two digits = 66\n",
        "\n",
        "k = 66\n",
        "\n",
        "np.random.seed(0)  # for reproducibility\n",
        "exam_scores = 70 + np.random.randint(0, 15, size=12) + (k % 5)\n",
        "\n",
        "\n",
        "print(\"Sample Exam Scores:\", exam_scores)"
      ],
      "metadata": {
        "id": "qShdIun6i4aI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hypothesized_mean = 65"
      ],
      "metadata": {
        "id": "w9QsVpNQjYvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_statistic, p_value = stats.ttest_1samp(exam_scores, popmean=hypothesized_mean)\n",
        "sample_mean = np.mean(exam_scores)\n",
        "df = len(exam_scores) - 1\n",
        "\n",
        "print(\"\\nSample Mean:\", sample_mean)\n",
        "print(\"Hypothesized Mean:\", hypothesized_mean)\n",
        "print(\"t-Statistic:\", t_statistic)\n",
        "print(\"Degrees of Freedom:\", df)\n",
        "print(\"p-Value:\", p_value)"
      ],
      "metadata": {
        "id": "m6Y0ug--jmM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confidence_level = 0.99  # For alpha=0.01\n",
        "sem = stats.sem(exam_scores)  # Standard Error of the Mean\n",
        "ci = stats.t.interval(confidence_level, df, loc=sample_mean, scale=sem)\n",
        "print(\"\\n99% Confidence Interval for Sample Mean:\", ci)"
      ],
      "metadata": {
        "id": "sq33qPG0jxVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.01\n",
        "if p_value < alpha:\n",
        "    decision = \"Reject H0: The population mean is significantly different from 65. H1 wins.\"\n",
        "else:\n",
        "    decision = \"Fail to reject H0: No significant difference from 65. H0 wins.\"\n",
        "\n",
        "print(\"\\nDecision:\", decision)"
      ],
      "metadata": {
        "id": "j93D7zMkj-n9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.errorbar(x=[0], y=[sample_mean], yerr=[sem], fmt='o', capsize=10, label='Sample Mean ± 1 SE', color='blue')\n",
        "plt.axhline(hypothesized_mean, color='red', linestyle='--', label='Hypothesized Mean (65)')\n",
        "plt.xlim(-1,1)\n",
        "plt.xticks([])\n",
        "plt.ylabel('Exam Scores')\n",
        "plt.title('One-Sample t-Test Visualization - Case 1')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B8yejWvulWqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Case 2: H0 wins (p-value > 0.01)"
      ],
      "metadata": {
        "id": "Case2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# last two digits = 66\n",
        "\n",
        "k = 66\n",
        "\n",
        "np.random.seed(0)  # for reproducibility\n",
        "exam_scores = 60 + np.random.randint(0, 15, size=12) + (k % 5)\n",
        "\n",
        "\n",
        "print(\"Sample Exam Scores:\", exam_scores)"
      ],
      "metadata": {
        "id": "qShdIun6i4aI_case2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hypothesized_mean = 65"
      ],
      "metadata": {
        "id": "w9QsVpNQjYvu_case2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_statistic, p_value = stats.ttest_1samp(exam_scores, popmean=hypothesized_mean)\n",
        "sample_mean = np.mean(exam_scores)\n",
        "df = len(exam_scores) - 1\n",
        "\n",
        "print(\"\\nSample Mean:\", sample_mean)\n",
        "print(\"Hypothesized Mean:\", hypothesized_mean)\n",
        "print(\"t-Statistic:\", t_statistic)\n",
        "print(\"Degrees of Freedom:\", df)\n",
        "print(\"p-Value:\", p_value)"
      ],
      "metadata": {
        "id": "m6Y0ug--jmM6_case2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confidence_level = 0.99  # For alpha=0.01\n",
        "sem = stats.sem(exam_scores)  # Standard Error of the Mean\n",
        "ci = stats.t.interval(confidence_level, df, loc=sample_mean, scale=sem)\n",
        "print(\"\\n99% Confidence Interval for Sample Mean:\", ci)"
      ],
      "metadata": {
        "id": "sq33qPG0jxVN_case2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.01\n",
        "if p_value < alpha:\n",
        "    decision = \"Reject H0: The population mean is significantly different from 65. H1 wins.\"\n",
        "else:\n",
        "    decision = \"Fail to reject H0: No significant difference from 65. H0 wins.\"\n",
        "\n",
        "print(\"\\nDecision:\", decision)"
      ],
      "metadata": {
        "id": "j93D7zMkj-n9_case2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.errorbar(x=[0], y=[sample_mean], yerr=[sem], fmt='o', capsize=10, label='Sample Mean ± 1 SE', color='blue')\n",
        "plt.axhline(hypothesized_mean, color='red', linestyle='--', label='Hypothesized Mean (65)')\n",
        "plt.xlim(-1,1)\n",
        "plt.xticks([])\n",
        "plt.ylabel('Exam Scores')\n",
        "plt.title('One-Sample t-Test Visualization - Case 2')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B8yejWvulWqx_case2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part D: Mini Creative Task"
      ],
      "metadata": {
        "id": "PartD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a courtroom trial, hypothesis testing mirrors the judicial process where the null hypothesis (H0) assumes the defendant is innocent until proven guilty. The alternative hypothesis (H1) posits that the person is guilty. The p-value measures the strength of the evidence brought forward by the lawyer (prosecution); a low p-value suggests compelling evidence against the defendant's innocence. Alpha (α) represents the judge's strictness level, similar to the 'beyond a reasonable doubt' standard, setting the bar for how strong the evidence must be to convict. If the p-value is less than or equal to α, the judge rejects H0 and rules in favor of H1, finding the defendant guilty. Conversely, if the p-value exceeds α, there isn't sufficient evidence to reject H0, so the defendant is acquitted (innocent). This framework protects against wrongful convictions, much like controlling Type I errors in statistics."
      ],
      "metadata": {
        "id": "Paragraph"
      }
    }
  ]
}